# FastAPI Chatbot

This FastAPI project provides CRUD endpoints for managing users and a WebSocket-based chatbot API powered by the OpenAI GPT-3.5-turbo LLM model. The CRUD endpoints allow users to perform operations such as creating, retrieving, updating, and deleting user records. Additionally, the chat endpoint enables users to interact with the chatbot by providing a user ID and a message, which then generates a response based on the conversation history.

## Endpoints

### User Endpoints

1. Create User: `POST /api/v1/users` Create a new user with provided details.

2. Get List of Users: `GET /api/v1/users` Retrieve a list of all users.

3. Get User by ID: `GET /api/v1/users/{user_id}` Retrieve user details by their ID.

4. Update User: `PUT /api/v1/users/{user_id}` Update an existing user's details.

5. Delete User: `DELETE /api/v1/users/{user_id}` Delete a user by their ID.

### Chatbot Endpoint

1. Chat API: `WebSocket POST /users/{user_id}/chat` Establish a WebSocket connection with a user ID to interact with the chatbot. Input a message to receive a response generated by the GPT-3.5-turbo LLM model. The chat API maintains a memory of the conversation, typically about the last 3 messages

## Configuration

### Database

- The project utilizes PostgreSQL as the database.
- User CRUD operations, along with conversations saved in the database, are managed through the database.

### Docker

- Docker and Docker Compose are used to run the project.
- The docker-compose.yml file contains configurations for both the PostgreSQL database and the API service.

### Database Migrations

- Database migrations are managed using Alembic.
- Ensure to run migrations before deploying the project to keep the database schema up to date.

## Running the Project

1. Clone the repository.
2. Navigate to the project directory.
3. Run `cp .env.example .env` to create a `.env` file based on the provided example.
4. Edit the `.env` file and add the necessary environment variables, such as database connection strings and OPENAI_API_KEY tokens.
5. Run `docker-compose up` to start the PostgreSQL database and API service.
6. User CRUD endpoints are accessible on the Swagger UI generated by FastAPI, which can be accessed at [http://localhost:8000/docs](http://localhost:8000/docs).
7. **Note**: Before testing the chatbot endpoint, create a user and pass its ID to the chatbot endpoint.
8. A WebSocket client for interacting with the chatbot endpoint is available.
   - Exec into the API container and run the `test_chatbot.py` script to interact with the chatbot.
   - Command to run the `test_chatbot.py` script inside the API container: `python test_chatbot.py`

## Dependencies

- FastAPI: Web framework for building APIs with Python.
- SQLAlchemy: SQL toolkit and Object-Relational Mapping (ORM) library.
- OpenAI: Provides the GPT-3.5-turbo LLM model for generating chatbot responses.
  **Note**: An OpenAI API token and key are required.
- Alembic: Database migration tool for SQLAlchemy.
- Docker: Containerization platform for easy deployment.
- Docker Compose: Tool for defining and running multi-container Docker applications.

## Notes

- Ensure proper configuration of environment variables for database connection strings, and API keys for security and scalability in production environments.
- Monitor and manage resource utilization, especially OPENAI_KEY consumption, to ensure optimal performance of the chatbot API and database operations.
